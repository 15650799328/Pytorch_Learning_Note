{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Extension to Pytorch tutorial's [Classifying Names with a Character-Level RNN](http://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html#classifying-names-with-a-character-level-rnn). The main purpose of this script is to demo batch bi-RNN on classification when input dataset has various length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29fe9cbb690>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import glob, os, string\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "all_letters = string.ascii_letters + \":.,-\\n \"\n",
    "n_letters = len(all_letters)\n",
    "path_to_files = \"./data/names/*.txt\"\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "### Process data into a long list [ (language name, country name),...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_files):\n",
    "    files = glob.glob(path_to_files)\n",
    "    country_name = [os.path.basename(file).split(\".\")[0] for file in files]\n",
    "    name_data = []\n",
    "    for file, file_name in zip(files, country_name):\n",
    "        with open(file, 'r') as f:\n",
    "            names = f.readlines()\n",
    "        name_data += [(name.strip()+\"\\n\", file_name) for name in names]\n",
    "    return list(set(name_data)), country_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert characters into numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_idx(dat):\n",
    "    to_ix = {k: v for v, k in enumerate(dat)}\n",
    "    ix_to = {v: k for k, v in to_ix.items()}\n",
    "    return to_ix, ix_to\n",
    "\n",
    "def sort_batch_data(dat):\n",
    "    # data: [[(name, target), len of name], ...]\n",
    "    name, target = dat[0]\n",
    "    length = dat[1]\n",
    "    sorted_length, sorted_id = length.sort(dim=0, descending=True)\n",
    "    sorted_name = name[sorted_id]\n",
    "    sorted_target = target[sorted_id]\n",
    "    return Variable(torch.t(sorted_name)), Variable(sorted_target).squeeze(), sorted_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset via Pytorch's DataLoader\n",
    "1. Input data format: [ (language name, country name), ... ] \n",
    "2. Create two torch long tensor with zeros:\n",
    "\tcharacter_tensor ( n samples, length of longest name)\n",
    "\ttarget_tensor  (n samples, 1)\n",
    "3. Convert input data into both tensors. For example, if the longest name has length of 4, a name with length of 2 will be padded 2 zeros at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataset(data.Dataset):\n",
    "    def __init__(self, data, char_to_idx, target_to_idx):\n",
    "        super(NameDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.names = [x[0] for x in data]\n",
    "        self.targets = [x[1] for x in data]\n",
    "        self.n_sampel = len(self.data)\n",
    "        self.length = [len(x[0]) for x in self.data]\n",
    "\n",
    "        self.char_to_idx = char_to_idx\n",
    "        self.target_to_idx = target_to_idx\n",
    "        self.char_tensor = torch.zeros((self.n_sampel, max(self.length))).long()\n",
    "        self.target_tensor = torch.zeros((self.n_sampel, 1)).long()\n",
    "        self.process_data()\n",
    "\n",
    "    def process_data(self):\n",
    "        for i in range(self.n_sampel):\n",
    "            name, target = self.data[i]\n",
    "            self.char_tensor[i, :self.length[i]] = self.convert_to_tensor(name, self.char_to_idx)\n",
    "            self.target_tensor[i, :] = self.convert_to_tensor([target], self.target_to_idx)\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_tensor(char, idx):\n",
    "        return torch.LongTensor([idx[i] for i in char])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return [(self.char_tensor[index], self.target_tensor[index]), self.length[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The RNN Model:\n",
    "1. Character level embedding \n",
    "2. LSTM or GRU: bi-directional with dropout rate of 0.7\n",
    "3. Linear combination \n",
    "4. Sum over all character values\n",
    "5. Softmax \n",
    "6. Gradient clipping\n",
    "7. Adam optimization with L2 regularization  of 0.0005. Initial learning rate is 1e-3\n",
    "8. Learning rate declining  scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNet(nn.Module):\n",
    "    def __init__(self, vocab_size, vocab_embed, hidden_dim, target_size, type):\n",
    "        super(RecurrentNet, self).__init__()\n",
    "        self.vocab_embed = vocab_embed\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, vocab_embed)\n",
    "        if type =='LSTM':\n",
    "            self.rnn = nn.LSTM(vocab_embed, hidden_dim//2, num_layers=1, bias=True, bidirectional=True, dropout=0.7)\n",
    "        elif type == 'GRU':\n",
    "            self.rnn = nn.GRU(vocab_embed, hidden_dim//2, num_layers=1, bias=True, bidirectional=True, dropout=0.7)\n",
    "        else:\n",
    "            raise SyntaxError(\"Type Error. Either LSTM or GRU\")\n",
    "        self.type = type\n",
    "        self.char_2_tag = nn.Linear(hidden_dim, target_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.type == \"LSTM\":\n",
    "            hidden_layers = (Variable(torch.zeros((2, batch_size, self.hidden_dim // 2))),\n",
    "                             Variable(torch.zeros((2, batch_size, self.hidden_dim // 2))))\n",
    "        elif self.type == 'GRU':\n",
    "            hidden_layers = Variable(torch.zeros((2, batch_size, self.hidden_dim // 2)))\n",
    "        return hidden_layers\n",
    "\n",
    "    def forward(self, name_tensor, sorted_length):\n",
    "        embed_name = self.embed(name_tensor)\n",
    "        packed_name = pack_padded_sequence(embed_name, sorted_length.tolist())\n",
    "        char_gru, char_hidden = self.rnn(packed_name, self.hidden)\n",
    "        pad_char, _ = pad_packed_sequence(char_gru)\n",
    "        target_space = self.char_2_tag(pad_char)\n",
    "        target_space = target_space.sum(dim=0)\n",
    "        target_score = self.softmax(target_space)\n",
    "        return target_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train/dev/test data\n",
    "The input data has various counts for each country, so I split it by weights of each country. \n",
    "\n",
    "Train: 80%  used to build the model\n",
    "\n",
    "Dev : 10%  used to configure model parameters\n",
    "\n",
    "Test : 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, test_size=0.2, train_size=0.8, random_state=1):\n",
    "    splitter = StratifiedShuffleSplit(test_size=test_size,\n",
    "                                      train_size=train_size,\n",
    "                                      random_state=random_state)\n",
    "    y_true = [x[1] for x in data]\n",
    "    for train_index, test_index in splitter.split(data, y_true):\n",
    "        train = [data[i] for i in train_index]\n",
    "        test = [data[i] for i in test_index]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Finnimore\\n', 'English'), ('Hinds\\n', 'English'), ('Tai\\n', 'Chinese'), ('Exton\\n', 'English'), ('Miyamae\\n', 'Japanese')]\n",
      "['Arabic', 'Chinese', 'English', 'Japanese', 'Korean']\n"
     ]
    }
   ],
   "source": [
    "name_data, countries = load_data(path_to_files)\n",
    "print(name_data[:5])\n",
    "print(countries[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set 4084\n"
     ]
    }
   ],
   "source": [
    "train, test_ = split_data(name_data, test_size=0.2, train_size=0.8, random_state=1)\n",
    "print(\"Length of training set {}\".format(len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dev set 511;\n",
      "length of test set 511.\n"
     ]
    }
   ],
   "source": [
    "dev, test = split_data(test_, test_size=0.5, train_size=0.5, random_state=2)\n",
    "print(\"Length of dev set {};\\nlength of test set {}.\".format(len(dev),len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix, ix_to_char = prepare_idx(all_letters)\n",
    "target_to_ix, ix_to_target = prepare_idx(countries)\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = NameDataset(train, char_to_ix, target_to_ix)\n",
    "train_data = DataLoader(train_set, batch_size, shuffle=True)\n",
    "\n",
    "dev_set = NameDataset(dev, char_to_ix, target_to_ix)\n",
    "dev_data = DataLoader(dev_set, batch_size, shuffle=True)\n",
    "\n",
    "test_set = NameDataset(test, char_to_ix, target_to_ix)\n",
    "test_data = DataLoader(test_set, len(test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up backprop, I clip gradientss that are larger than 10 and add a learning rate declinding scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(char_to_ix)\n",
    "target_size = len(target_to_ix)\n",
    "vocab_embed = 80\n",
    "hidden_dim = 60\n",
    "iterations = 10\n",
    "\n",
    "model = RecurrentNet(vocab_size, vocab_embed, hidden_dim, target_size, \"LSTM\")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.0005)\n",
    "optim_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, verbose=True, patience=1)\n",
    "loss_cache = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : 38.08849\n",
      "Epoch 2 : 22.18404\n",
      "Epoch 3 : 17.12583\n",
      "Epoch 4 : 14.36953\n",
      "Epoch 5 : 12.81506\n",
      "Epoch 6 : 11.73068\n",
      "Epoch 7 : 10.74078\n",
      "Epoch 8 : 10.23288\n",
      "Epoch 9 : 9.61407\n",
      "Epoch 10 : 9.01092\n"
     ]
    }
   ],
   "source": [
    "for i in range(iterations):\n",
    "    total_loss = []\n",
    "    for batch_data in train_data:\n",
    "        name, target, length = sort_batch_data(batch_data)\n",
    "        batch_size = len(length)\n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden(batch_size)\n",
    "        target_score = model(name, length)\n",
    "        loss = loss_fn(target_score, target)\n",
    "        loss.backward()\n",
    "        clip_grad_norm(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        total_loss.append(loss.data[0] * batch_size)\n",
    "    loss_avg = sum(total_loss) / len(total_loss)\n",
    "    optim_scheduler.step(loss_avg)\n",
    "    print(\"Epoch {} : {:.5f}\".format(i+1, loss_avg))\n",
    "    loss_cache.append(loss_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29fecb6d048>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29feba29dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_cache)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Main metric is average accuracy. Additional scores such as F1 and confusion matrix are used to analysis error. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(data):\n",
    "    # post-process data from data loader\n",
    "    target_pred = []\n",
    "    target_true = []\n",
    "    for batch_data in data:\n",
    "        name, target, length = sort_batch_data(batch_data)\n",
    "        batch_size = len(length)\n",
    "        model.hidden = model.init_hidden(batch_size)\n",
    "        target_score = model(name, length)\n",
    "        score, category = torch.max(target_score, dim=1)\n",
    "        target_pred += category.data.tolist()\n",
    "        target_true += target.data.tolist()\n",
    "    return target_pred, target_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate is 0.9591\n"
     ]
    }
   ],
   "source": [
    "target_pred, target_true = evaluation(train_data)\n",
    "accuracy = accuracy_score(target_true, target_pred)\n",
    "print(\"Accuracy rate is {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Arabic       0.76      0.43      0.55        86\n",
      "    Chinese       0.77      0.91      0.84       197\n",
      "    English       0.98      0.99      0.98      2934\n",
      "   Japanese       0.98      0.96      0.97       792\n",
      "     Korean       0.66      0.44      0.53        75\n",
      "\n",
      "avg / total       0.96      0.96      0.96      4084\n",
      "\n",
      "M_{i,j} where i is true group and j is predicted group\n",
      "\n",
      "['Arabic', 'Chinese', 'English', 'Japanese', 'Korean']\n",
      "[[  37    3   36    9    1]\n",
      " [   0  180    4    3   10]\n",
      " [   8   12 2905    5    4]\n",
      " [   3    7   18  762    2]\n",
      " [   1   32    8    1   33]]\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(target_true, target_pred, target_names=list(target_to_ix))\n",
    "print(report)\n",
    "\n",
    "error_matrix = confusion_matrix(target_true, target_pred)\n",
    "print(\"M_{i,j} where i is true group and j is predicted group\\n\")\n",
    "print(list(target_to_ix))\n",
    "print(error_matrix)\n",
    "\n",
    "y_true = [ix_to_target[i] for i in target_true]\n",
    "y_pred = [ix_to_target[i] for i in target_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dev Data Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate is 0.9315\n"
     ]
    }
   ],
   "source": [
    "target_pred, target_true = evaluation(dev_data)\n",
    "accuracy = accuracy_score(target_true, target_pred)\n",
    "print(\"Accuracy rate is {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Arabic       0.50      0.27      0.35        11\n",
      "    Chinese       0.59      0.83      0.69        24\n",
      "    English       0.98      0.98      0.98       367\n",
      "   Japanese       0.92      0.93      0.92        99\n",
      "     Korean       0.33      0.20      0.25        10\n",
      "\n",
      "avg / total       0.93      0.93      0.93       511\n",
      "\n",
      "M_{i,j} where i is true group and j is predicted group\n",
      "\n",
      "['Arabic', 'Chinese', 'English', 'Japanese', 'Korean']\n",
      "[[  3   0   4   4   0]\n",
      " [  0  20   1   1   2]\n",
      " [  1   4 359   1   2]\n",
      " [  2   4   1  92   0]\n",
      " [  0   6   0   2   2]]\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(target_true, target_pred, target_names=list(target_to_ix))\n",
    "print(report)\n",
    "\n",
    "error_matrix = confusion_matrix(target_true, target_pred)\n",
    "print(\"M_{i,j} where i is true group and j is predicted group\\n\")\n",
    "print(list(target_to_ix))\n",
    "print(error_matrix)\n",
    "\n",
    "y_true = [ix_to_target[i] for i in target_true]\n",
    "y_pred = [ix_to_target[i] for i in target_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate is 0.9335\n"
     ]
    }
   ],
   "source": [
    "target_pred, target_true = evaluation(test_data)\n",
    "accuracy = accuracy_score(target_true, target_pred)\n",
    "print(\"Accuracy rate is {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Arabic       0.50      0.18      0.27        11\n",
      "    Chinese       0.71      0.80      0.75        25\n",
      "    English       0.96      0.98      0.97       367\n",
      "   Japanese       0.93      0.96      0.95        99\n",
      "     Korean       0.33      0.22      0.27         9\n",
      "\n",
      "avg / total       0.93      0.93      0.93       511\n",
      "\n",
      "M_{i,j} where i is true group and j is predicted group\n",
      "\n",
      "['Arabic', 'Chinese', 'English', 'Japanese', 'Korean']\n",
      "[[  2   0   7   2   0]\n",
      " [  0  20   2   0   3]\n",
      " [  1   2 358   5   1]\n",
      " [  1   0   3  95   0]\n",
      " [  0   6   1   0   2]]\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(target_true, target_pred, target_names=list(target_to_ix))\n",
    "print(report)\n",
    "\n",
    "error_matrix = confusion_matrix(target_true, target_pred)\n",
    "print(\"M_{i,j} where i is true group and j is predicted group\\n\")\n",
    "print(list(target_to_ix))\n",
    "print(error_matrix)\n",
    "\n",
    "y_true = [ix_to_target[i] for i in target_true]\n",
    "y_pred = [ix_to_target[i] for i in target_pred]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
